#搜索引擎设计-索引器
----
[一、设计目的](#1)   
[二、设计目标](#2)   
[三、设计思路](#3)   
[四、实现](#4)   
[五、总结](#5)


##<h2 id ='1'>一、设计目的</h2>
* 了解并熟悉搜索引擎**倒排索引**的工作原理
* 了解并熟悉多文件格式的内容__提取__
* 进一步学习python语言


##<h2 id = '2'>二、设计目标</h2>
* 使用Python设计一个能够建立倒排索引的程序
* 能够提取本地多种格式的文件的内容，包括__txt__、__word__文档、__rtf__文档、__excel__文档、__html__文档、__xml__文档
* 能建立__正向索引__
* 能建立__反向索引__
* 有完善的__设计文档__


##<h2 id = '3'>三、设计思路</h2>
> 1.从上一次__设计爬虫__时抓取到的记录中检索本次实验需要处理的文档的__信息__，根据不同的后缀区分__文件格式__，调用不同的__函数__进行转换为__纯文本文档__。   
> 2.打开转换格式之后的纯文本文档，使用__结巴分词__将整篇文章进行__分词__，对单个文档的分词结果进行整理得到__正排索引__。   
> 3.整理得到的正排索引，利用python的__字典__特性给每个词建立__倒排索引__。   
> 4.读取倒排索引，建立一个简单的**查询**功能


##<h2 id = '4'>四、实现</h2>

* **转换器Converter** 

> * 转换器在Converter当中，包含了__doc,docx,rtf,excel,html,xml__到txt的__转换函数__，以及__真实路径__映射到用于记录的__短路径__的相互转换函数，
> * 长路径为__绝对路径__，短路径用于保存在正、倒排索引中，减少__冗余数据__，达到减少内存和硬盘开销的目的
> * 各个转换函数的统一参数如下：
> * **result\_path = [file\_type]\_2\_txt (local\_file\_path)**
> 
>  > |关键字|类型|意义|
>  > |---|---|---|
>  > |result_path|文件路径|转换后的txt文件的绝对路径|
>  > |file_type|文件类型|等待被转换的文件类型|
>  > |local\_file\_path|文件路径|等待被转换的文件的绝对路径|
> * 函数**doc\_2\_txt**，**docx\_2\_txt**，**rtf\_2\_txt**使用了__OS X__的系统命令`textutil -convert txt [local_file_path]`进行转换。python使用os包下的os.system调用系统命令。
> * 函数**html\_2\_txt**调用了BeautifulSoup，清除style和script，使用正则表达式清洗了html标签
>   
 		#清除qstyle和script
		[script.extract() for script in htmlsoup.findAll('script')]
		[style.extract() for style in htmlsoup.findAll('style')]
		#通过正则表达式清除html标签
		reg1 = re.compile("<[^>]*>")
		content = reg1.sub('',htmlsoup.prettify())
	
> * 函数**pdf\_2\_txt**的功能实现起来比较复杂，单独放在了包**pdf\_2\_txt\_test.py**当中，这个文件使用了包**pdfminer**作为转换工具
> * 函数**xls\_2\_txt**实现的是将word文档转换为txt格式，使用了**xlrd**来进行读取
> * **realpath\_2\_short**负责将完整的*绝对路径*切割，返回较短的*相对路径*，**shortpath\_2\_real**负责将较短的*相对路径*还原为*绝对路径*
  

* **分词器Segmenter**

> * 分词器在__Segmenter__当中，使用__结巴分词__作为分词工具   
> * 出于需要加载停用词表的考量，将__分词器__整理为一个对象，这个对象在整个系统__初始化__时被生成，同时加载__停用词表__，其生命周期几乎贯穿整个程序。
> * 停用词表以__list__形式放在__self.stop\_word__当中，同时添加一些__不可见的符号__，如'\\n','\\r','\\r\\n'
> 
> * *分词器的函数设计*
>  >|编号|函数名|用途|
>  >|---|---|---|
>  >|01|\_\_init\_\_|初始化|
>  >|02|seg_words|将给定的字符串进行分词|
> 
> * 各个函数参数及返回值
> 
>  01.\_\_init\_\_
>  >|参数|类型|意义|
>  >|---|---|---|
>  >|self|指针||
>  >|stop_words|list|停用词表|
> 
>  >|返回值|类型|意义|
>  >|---|---|---|
>  >|无|||
> 
>  02.seg\_words
>  >|参数|类型|意义|
>  >|---|---|---|
>  >|self|指针||
>  >|contents|字符串|需要被分词的内容|
> 
>  >|返回值|类型|意义|
>  >|---|---|---|
>  >|result_list|list|分词的结果,没有去重，没有整理顺序|

* **分析器Analyser**

> * 分析器**Analyser**是这个程序的主要构成，负责生成**分词器**，加载需要建立索引的文件，找到转换这些文件需要的**转换函数**，建立**正排索引**和**倒排索引**，并将**结果**保存到本地。
> 
> * 必须要说明的几个宏定义
> 
>  >|定义名|类型|意义|
> >|---|---|---|
> >|LOCAL\_HTML\_FILEPATH|文件夹路径|本地的html文件存放的位置|
> >|LOCAL\_RESOURCES\_FILEPATH|文件夹路径|本地资源文件存放的位置|
> >|REVERSER\_INDEX\_PATH|文件路径|倒排结果存放在本地的路径|
> >|URL\_LIST|文件路径|html链接到本地文件的映射文件|
> >|RESOURCES_LIST|文件路径|资源链接到本地文件的映射文件|
> >|STOP\_WORDS\_PATH|文件路径|停用词表的存放位置|
> 
> * *分析器的工作主要包括以下几个步奏：*
> 
>  1. **init(STOP_WORDS_PATH)**加载**停用词表**，返回一个已经整理好停用词表的**分词器**
> 
>  2. 将**资源连接映射文件地址**、**html链接映射地址**、**资源文件存放位置**、**html存放位置**以及**分词器**传递给函数**load_pages**
> 
>  3. **load_pages**创建一个**空**的字典**word_dict**，往**build\_reverser\_index**函数中传入**分词器**，**字典**，**资源文件（html文件）映射**和这些文件存放的**位置**
>  4. **build\_reverser\_index**读取映射文件当中的记录，对每条**记录**使用**convert_page**进行格式转换，如果转换**成功**，则读取转换的结果，使用**segment_word**进行分词,分词完成后**Build_Forward_Index**建立正排索引，然后依据正排索引建立**倒排索引**。
>  5. **convert_page**使用了**cur\_local\_name**从记录中截取本地路径，以及这个记录在本地文件的**后缀**，通过后缀判断这个文件应该被转交到哪一个转换器函数进行转换
> 
> * *解析函数设计*
> 
>  >|编号|函数名|用途|
> >|----|---|----|
> >|01|init|初始化|
> >|02|load\_page|处理文档|
> >|03|build\_reverser\_index|针对某一类文件建立倒排索引|
> >|04|convert\_page|转换文件格式|
> >|05|cut\_local\_name|从记录中切割本地文件路径|
> >|06|segment_page|对给定的文件进行分词|
> >|07|Build\_Forward\_Index|建立正排索引|
> >|08|save\_words\_table|保存正排索引|
> >|09|save\_index|保存倒排索引|
> 
> * *各个函数参数及返回值*
> 
> 01. **init**
>  
>  >|参数|类型|意义|
>  >|---|---|---|
>  >|STOP_WORDS_PATH|文件路径|停用词表的存放位置|
> 
>  >|返回值|类型|意义|
>  >|---|---|---|
>  >|segmenter|分词器|保存了停用词表的分词器|
> 
> 02. **load_page**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|resources\_list\_path|文件路径|资源链接保存到本地的映射文件的位置|
> >|url\_list\_path|文件路径|html链接保存到本地的映射文件的位置|
> >|local\_html\_filepath|文件夹路径|html文件保存在本地的位置|
> >|local\_resources\_filepath|文件夹路径|资源文件保存在本地的位置|
> >|segmenter|分词器|分词器|
> 
>  >|返回值|类型|意义|
>  >|---|---|---|
>  >|无|||
> 
> 03. **build\_reverser\_index**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|segmenter|分词器|分词器|
> >|word\_dict|字典|保存倒排索引|
> >|file\_list\_path|文件路径|链接到本地路径的映射文件的位置|
> >|local\_file\_path|文件夹路径|这类文件存放的文件夹的位置|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|无|||
> 
> 04. **convert_page**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|resources\_record|映射记录|映射文件中的单条记录|
> >|local\_file\_path|文件夹路径|保存这类文件的文件夹的位置|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|item\_path|文件路径|这个映射对应本地的路径|
> >|local\_txt\_path|文件路径|转换结果|
> 
> 05. **cut_local_name**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|resources\_record|映射记录|映射文件中的单条记录|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|item_path|文件路径|这条记录对应的文件在本地的位置|
> >|suffix|字符串|这条记录对应的文件的后缀 |
> 
> 06. **segment_page**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|local\_txt\_path|文件路径|等待被分词的纯文本文件的路径|
> >|segmenter|分词器|分词器|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|words\_in\_pages|list|这个文件的分词结果|
> 
> 07. **Build\_Forward\_Index**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|word\_in\_page|list|某一个文件分词的结果|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|word\_dict|字典|正排索引的结果，包含词频|
> 
> 08. **save\_words\_table**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|item_path|文件路径|需要被保存的分词结果的源文件路径|
> >|wordlist|list|分词结果|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|无|||
> 
> 09. **save\_index**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|word_dict|字典|完整的倒排索引|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|无|||

* **查询工具Query**

> * 查询工具**Query**是额外实现的一个部分，简单地利用了之前倒排索引的结果进行查询。
> * **Query**能够对输入的句子进行分词然后查询，但是没有做完善的排序，只有简单的按照**词频**从高到低输出
> * **Query**使用到之前用的分词工具，因为时间紧迫没有重写代码，而是单独保留并使用了之前分析器生成**分词器**的部分。
> * **Query**的输入以exit为结束标志
> * **Query**的各个函数设计：
> 
>  >|编号|函数名|用途|
> >|---|---|---|
> >|1|Init|生成分词器，根据分析器的结果读取倒排索引|
> >|2|main|负责循环接收接收指令|
> >|3|Query|查询某个词的结果|
> >|4|show\_query\_result|输出某个词的查询结果|
> >|5|show\_one\_result|输出这个词的单独一项结果|
> >|6|get\_result\_in\_one\_line|将包含被查询的词的一行，在这个词附近的内容进行输出|
> 
> * 各个函数的参数及返回值
> 
> 1. **Init**
> 
>  >|参数|类型|意义|
> >|---|---|---|
> >|words_path|文件路径|倒排索引的存放位置|
> >|words_dict|字典|用于在内存中保存倒排索引|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|seg|分词器|加载好了停用词表的分词器|
> 
> 2. **main**
> 
>  >|参数|类型|意义|
> >|---|---|---|
> >|words_dict|字典|倒排索引|
> >|seg|分词器|分词器|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|无|||
> 
> 3. **Query**
> 
>  >|参数|类型|意义|
> >|---|---|---|
> >|query_word|字符串|需要被查询的单词|
> >|words_dict|字典|倒排索引|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|无|||
> 
> 4. **show\_query\_result**
> 
>  >|参数|类型|意义|
> >|---|---|---|
> >|query_result|二元组的list|某个词的查询结果，这个二元组的第一项为包含被查询词的文件路径，第二项为词频|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|无|||
> 
> 5. **show\_one\_result**
> 
>  >|参数|类型|意义|
> >|---|---|---|
> >|result|单项查询结果|包含某个词的文件，在这个结果里包含文件的地址和这个词出现的词频|
> >|query_word|字符串|被查询的词|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|无|||
> 
> 6. **get\_result\_in\_line**
>  
>  >|参数|类型|意义|
> >|---|---|---|
> >|line|字符串|包含被查询单词的某一行|
> >|query_word|字符串|被查询的单词|
> 
>  >|返回值|类型|意义|
> >|---|---|---|
> >|result_line|字符串|将原始的字符串切割后，得到被查询词附近的内容|

## <h2 id = '5'>五、总结</h2>

* 尚待改进的地方

 1. 这次的代码比上一次更混乱了，熟悉了python之后反而写的更加随意，以后需要注意。变量和函数的命名也没有注意规范。
 2. 倒排索引存放在内存中。在这次任务里，被保存的词汇量不大，而且页面总数也不多，倒排索引能够放在内存里。考虑到以后做一个比较完善的爬虫，倒排索引可能会根据不同的词存放在内存的不同位置。
 3. 没有比较好的自定义分词词典的接口，也没有比较好的编辑停用词表的接口，也没有对分词的结果进行非常完整的测试，仅仅是保证了分出来的词能够用于建立倒排索引。一些不太合理的分词也没有加入停用词表进行处理。
 4. 需要好好学习正则表达式
 5. 查询器的逻辑非常混乱

* 感想   
	总算是把第二个作业完成了。考研时间比较紧，很多问题已经注意到却没有时间去好好解决，只好用各种奇奇怪怪的办法进行修修补补。下一次作业应该要在十二月考完研以后了。